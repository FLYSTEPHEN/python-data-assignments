{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      keyword  frequency\n",
      "0       china         93\n",
      "1       trade         58\n",
      "2     chinese         51\n",
      "3         war         38\n",
      "4       trump         32\n",
      "5     beijing         25\n",
      "6       would         22\n",
      "7     tariffs         22\n",
      "8        said         20\n",
      "9        more         18\n",
      "10    against         16\n",
      "11  president         15\n",
      "12    america         15\n",
      "13   american         14\n",
      "14       deal         14\n",
      "CPU times: user 73.7 ms, sys: 5.35 ms, total: 79 ms\n",
      "Wall time: 79.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "import os #用於讀取文件列表\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "pd.set_option('max_rows',2000)\n",
    "pd.set_option('max_colwidth',100)\n",
    "punctuation += '\\\"“”‘’—-–'\n",
    "\n",
    "def list_documents(path): #將待處理的文件以list輸出\n",
    "    list_txt = []\n",
    "    list_file = os.listdir(path) #讀取目錄下所有文件的路徑\n",
    "    list_file.remove('stopword.txt')\n",
    "    for i in list_file:\n",
    "        if i.find('.txt') != -1: #如果文件是.txt文件\n",
    "            list_txt.append(i)\n",
    "    list_txt.sort()\n",
    "    n = len(list_txt)\n",
    "    return list_txt, n #n是文件數量\n",
    "\n",
    "\n",
    "def count_frequency(text):\n",
    "    def kill_punctuations_capitals(text): \n",
    "        text = text.replace(\"’s\",\"\") #需要先去除‘s，否則去除標點會留下如chinas，truups這樣的詞\n",
    "        translator = str.maketrans(\"\",\"\",punctuation) \n",
    "        #等價於translator = str.maketrans(punctuation,len(punctuation)*' ')\n",
    "        #note:str.maketrans(input,output,delete)，input,output長度必須相等\n",
    "        list_lowercase_without_punctuation = text.lower().translate(translator).split()\n",
    "        #將大寫字母轉化為小寫，去除標點，列出單詞\n",
    "        return list_lowercase_without_punctuation\n",
    "\n",
    "\n",
    "    def extract_meaningful(list): #去除無意義的單詞\n",
    "        list_meaningful_words = []\n",
    "        with open ('stopword.txt','r') as s:\n",
    "            list_stop_words = s.read().split() #讀取stoplist\n",
    "        for m in list:\n",
    "            if m not in list_stop_words:\n",
    "                list_meaningful_words.append(m)\n",
    "        return list_meaningful_words\n",
    "\n",
    "    def words_frequency(list): #統計一篇文章中的frequency\n",
    "        dict_words_frequency={}\n",
    "        for m in list:\n",
    "            dict_words_frequency[m]=list.count(m)\n",
    "        return dict_words_frequency\n",
    "    return words_frequency(extract_meaningful(kill_punctuations_capitals(text)))\n",
    "\n",
    "\n",
    "def update_dict(dict0,dict1): #兩個txt中的frequency相加\n",
    "    for k,v in dict1.items():\n",
    "        if dict0.__contains__(k):\n",
    "            dict0[k] += v\n",
    "        else:\n",
    "            dict0.update({k : dict1[k]})\n",
    "\n",
    "def rank_frequency(dict): #根據frequency排序，也可以最後用print(s.sort_values(ascending=False))，但是不方便寫cvs\n",
    "    dict_frequency_rank={}\n",
    "    rank = sorted(dict.items(), key=lambda item: item[1], reverse=True) \n",
    "    #將字典轉化爲二元數組，並根據字典中value排序\n",
    "    for m in range(0,len(rank)):\n",
    "        dict_frequency_rank.update({rank[m][0]:rank[m][1]})\n",
    "    #再將字典重新整合起來\n",
    "    return dict_frequency_rank\n",
    "\n",
    "def write_cvs(dict):\n",
    "    with open('keywords_frequency.csv','w',newline='') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        header = ['keyword','frequency']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(dict.items())\n",
    "\n",
    "\n",
    "path = \"./\" #在py文件所在根目錄操作\n",
    "dict_accumulate_frequency = {} #所有文件中的frequency\n",
    "dict_text_frequency = {} #單個文件中的frequency，方便日後分析每個文件\n",
    "\n",
    "list_txt,n = list_documents(path) #讀取文件路徑，輸出文件列表\n",
    "for i in list_txt: #依次讀取\n",
    "    with open(i,'r') as t: #打開文件\n",
    "        text = t.read() #讀取文件中的文本\n",
    "    dict_text_frequency[i] = count_frequency(text) #計數一個文件\n",
    "    update_dict(dict_accumulate_frequency,dict_text_frequency[i]) #累計到dict_accumulate_frequency\n",
    "dict_frequency_rank = rank_frequency(dict_accumulate_frequency) #排序\n",
    "\n",
    "write_cvs(dict_frequency_rank)\n",
    "\n",
    "df = pd.read_csv('keywords_frequency.csv').head(15)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
