{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "name 'list' is parameter and global (<timed exec>, line 38)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/chao/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2961\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-e99a739cfea3>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'import csv\\nimport os #用於讀取文件列表\\nimport pandas as pd\\nfrom string import punctuation\\npd.set_option(\\'max_rows\\',2000)\\npd.set_option(\\'max_colwidth\\',100)\\npunctuation += \\'\\\\\"“”‘’—-–\\'\\n\\ndef list_documents(path): #將待處理的文件以list輸出\\n    list_txt = []\\n    list_file = os.listdir(path)\\n    list_file.remove(\\'stopword.txt\\')\\n    for i in list_file:\\n        if i.find(\\'.txt\\') != -1:\\n            list_txt.append(i)\\n    list_txt.sort()\\n    n = len(list_txt)\\n    return list_txt, n #n是文件數量\\n\\ndef frequency(text):\\n    text = text\\n    def kill_punctuations_capitals(text): #將大寫字母轉化為小寫，去除標點，列出單詞\\n        text = text.replace(\"’s\",\"\")\\n        translator = str.maketrans(\"\",\"\",punctuation) \\n        #translator = str.maketrans(punctuation,len(punctuation)*\\' \\') #note:str.maketrans(input,output,delete)\\n        list_lowercase_without_punctuation = text.lower().translate(translator).split()\\n        global list\\n        list = list_lowercase_without_punctuation\\n\\n\\n    def extract_meaningful(list): #去除無意義的單詞\\n        list_meaningful_words = []\\n        with open (\\'stopword.txt\\',\\'r\\') as s:\\n            list_stop_words = s.read().split() #讀取stoplist\\n        for m in list:\\n            if m not in list_stop_words:\\n                list_meaningful_words.append(m)\\n        global list\\n        list = list_meaningful_words\\n\\n    def words_frequency(list): #統計一篇文章中的frequency\\n        dict_words_frequency={}\\n        for m in list:\\n            dict_words_frequency[m]=list.count(m)\\n        global dict\\n        dict = dict_words_frequency\\n\\n    def rank_frequency(dict): #根據frequency排序，也可以最後用print(s.sort_values(ascending=False))，但是不方便寫cvs\\n        dict_frequency_rank={}\\n        rank = sorted(dict.items(), key=lambda item: item[1], reverse=True)\\n        for m in range(0,len(rank)):\\n            dict_frequency_rank.update({rank[m][0]:rank[m][1]})\\n        global dict\\n        dict = dict_frequency_rank\\n    return dict\\n\\ndef update_dict(dict0,dict1): #兩個txt中的frequency相加\\n    for k,v in dict1.items():\\n        if dict0.__contains__(k):\\n            dict0[k] += v\\n        else:\\n            dict0.update({k : dict1[k]})\\n            \\ndef write_cvs(dict):\\n    with open(\\'keywords_frequency.csv\\',\\'w\\',newline=\\'\\') as f:\\n        writer = csv.writer(f,delimiter=\\',\\')\\n        header = [\\'keyword\\',\\'frequency\\']\\n        writer.writerow(header)\\n        writer.writerows(dict.items())\\npath = \"./\"\\nlist_txt,n = list_documents(path)\\ndict_accumulative_frequency = {}\\ndict_list_frequency = {}\\nfor i in list_txt:\\n    with open(i,\\'r\\') as t:\\n        text = t.read()\\n    dict_list_frequency[i] = frequency(text)\\n    update_dict(dict_accumulative_frequency,dict_list_frequency[i])\\n\\ndict_frequency_rank = rank_frequency(dict_accumulative_frequency)\\nwrite_cvs(dict_frequency_rank)\\n    \\nprint(pd.DataFrame({\\'keywords in all files\\':pd.Series(dict_frequency_rank)}).head(15))')\n",
      "  File \u001b[1;32m\"/Users/chao/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2167\u001b[0m, in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(magic_arg_s, cell)\n",
      "  File \u001b[1;32m\"<decorator-gen-62>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35mtime\u001b[0m\n",
      "  File \u001b[1;32m\"/Users/chao/venv/lib/python3.7/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/Users/chao/venv/lib/python3.7/site-packages/IPython/core/magics/execution.py\"\u001b[0m, line \u001b[1;32m1218\u001b[0m, in \u001b[1;35mtime\u001b[0m\n    code = self.shell.compile(expr_ast, source, mode)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/codeop.py\"\u001b[0;36m, line \u001b[0;32m133\u001b[0;36m, in \u001b[0;35m__call__\u001b[0;36m\u001b[0m\n\u001b[0;31m    codeob = compile(source, filename, symbol, self.flags, 1)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<timed exec>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m name 'list' is parameter and global\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "import os #用於讀取文件列表\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "pd.set_option('max_rows',2000)\n",
    "pd.set_option('max_colwidth',100)\n",
    "punctuation += '\\\"“”‘’—-–'\n",
    "\n",
    "def list_documents(path): #將待處理的文件以list輸出\n",
    "    list_txt = []\n",
    "    list_file = os.listdir(path)\n",
    "    list_file.remove('stopword.txt')\n",
    "    for i in list_file:\n",
    "        if i.find('.txt') != -1:\n",
    "            list_txt.append(i)\n",
    "    list_txt.sort()\n",
    "    n = len(list_txt)\n",
    "    return list_txt, n #n是文件數量\n",
    "\n",
    "def frequency(text):\n",
    "    text = text\n",
    "    def kill_punctuations_capitals(text): #將大寫字母轉化為小寫，去除標點，列出單詞\n",
    "        text = text.replace(\"’s\",\"\")\n",
    "        translator = str.maketrans(\"\",\"\",punctuation) \n",
    "        #translator = str.maketrans(punctuation,len(punctuation)*' ') #note:str.maketrans(input,output,delete)\n",
    "        list_lowercase_without_punctuation = text.lower().translate(translator).split()\n",
    "        global list\n",
    "        list = list_lowercase_without_punctuation\n",
    "\n",
    "\n",
    "    def extract_meaningful(list): #去除無意義的單詞\n",
    "        list_meaningful_words = []\n",
    "        with open ('stopword.txt','r') as s:\n",
    "            list_stop_words = s.read().split() #讀取stoplist\n",
    "        for m in list:\n",
    "            if m not in list_stop_words:\n",
    "                list_meaningful_words.append(m)\n",
    "        global list\n",
    "        list = list_meaningful_words\n",
    "\n",
    "    def words_frequency(list): #統計一篇文章中的frequency\n",
    "        dict_words_frequency={}\n",
    "        for m in list:\n",
    "            dict_words_frequency[m]=list.count(m)\n",
    "        global dict\n",
    "        dict = dict_words_frequency\n",
    "\n",
    "    def rank_frequency(dict): #根據frequency排序，也可以最後用print(s.sort_values(ascending=False))，但是不方便寫cvs\n",
    "        dict_frequency_rank={}\n",
    "        rank = sorted(dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        for m in range(0,len(rank)):\n",
    "            dict_frequency_rank.update({rank[m][0]:rank[m][1]})\n",
    "        global dict\n",
    "        dict = dict_frequency_rank\n",
    "    return dict\n",
    "\n",
    "def update_dict(dict0,dict1): #兩個txt中的frequency相加\n",
    "    for k,v in dict1.items():\n",
    "        if dict0.__contains__(k):\n",
    "            dict0[k] += v\n",
    "        else:\n",
    "            dict0.update({k : dict1[k]})\n",
    "            \n",
    "def write_cvs(dict):\n",
    "    with open('keywords_frequency.csv','w',newline='') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        header = ['keyword','frequency']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(dict.items())\n",
    "path = \"./\"\n",
    "list_txt,n = list_documents(path)\n",
    "dict_accumulative_frequency = {}\n",
    "dict_list_frequency = {}\n",
    "for i in list_txt:\n",
    "    with open(i,'r') as t:\n",
    "        text = t.read()\n",
    "    dict_list_frequency[i] = frequency(text)\n",
    "    update_dict(dict_accumulative_frequency,dict_list_frequency[i])\n",
    "\n",
    "dict_frequency_rank = rank_frequency(dict_accumulative_frequency)\n",
    "write_cvs(dict_frequency_rank)\n",
    "    \n",
    "print(pd.DataFrame({'keywords in all files':pd.Series(dict_frequency_rank)}).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c74af1f5d5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def frequency(text):\n",
    "    def kill_punctuations_capitals(text): #將大寫字母轉化為小寫，去除標點，列出單詞\n",
    "        text = text.replace(\"’s\",\"\")\n",
    "        translator = str.maketrans(\"\",\"\",punctuation) \n",
    "        #translator = str.maketrans(punctuation,len(punctuation)*' ') #note:str.maketrans(input,output,delete)\n",
    "        list_lowercase_without_punctuation = text.lower().translate(translator).split()\n",
    "        list = list_lowercase_without_punctuation\n",
    "    \n",
    "    def extract_meaningful(list): #去除無意義的單詞\n",
    "        list_meaningful_words = []\n",
    "        with open ('stopword.txt','r') as s:\n",
    "            list_stop_words = s.read().split() #讀取stoplist\n",
    "        for m in list:\n",
    "            if m not in list_stop_words:\n",
    "                list_meaningful_words.append(m)\n",
    "        list = list_meaningful_words\n",
    "\n",
    "    def words_frequency(list): #統計一篇文章中的frequency\n",
    "        dict_words_frequency={}\n",
    "        for m in list:\n",
    "            dict_words_frequency[m]=list.count(m)\n",
    "        dict = dict_words_frequency\n",
    "\n",
    "    def rank_frequency(dict): #根據frequency排序，也可以最後用print(s.sort_values(ascending=False))，但是不方便寫cvs\n",
    "        dict_frequency_rank={}\n",
    "        rank = sorted(dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        for m in range(0,len(rank)):\n",
    "            dict_frequency_rank.update({rank[m][0]:rank[m][1]})\n",
    "        dict = dict_frequency_rank\n",
    "    return list\n",
    "\n",
    "text= \"china, China Usa dic as,\"\n",
    "print(frequency(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
