{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "pd.set_option('max_rows',2000)\n",
    "pd.set_option('max_colwidth',100)\n",
    "punctuation += '\\\"“”‘’—-–'\n",
    "\n",
    "def list_documents(path): #將待處理的文件以list輸出\n",
    "    list_txt = []\n",
    "    list_file = os.listdir(path)\n",
    "    list_file.remove('stopword.txt')\n",
    "    for i in list_file:\n",
    "        if i.find('.txt') != -1:\n",
    "            list_txt.append(i)\n",
    "    list_txt.sort()\n",
    "    n = len(list_txt)\n",
    "    return list_txt, n #n是文件數量\n",
    "\n",
    "def kill_punctuations_capitals(text):\n",
    "    text = text.replace(\"’s\",\"\")\n",
    "    translator = str.maketrans(\"\",\"\",punctuation) \n",
    "    #translator = str.maketrans(punctuation,len(punctuation)*' ') #note:str.maketrans(input,output,delete)\n",
    "    list_lowercase_without_punctuation = text.lower().translate(translator).split()\n",
    "    return list_lowercase_without_punctuation\n",
    "    #將大寫字母轉化為小寫，去除標點，列出單詞\n",
    "\n",
    "def extract_meaningful(list): \n",
    "    list_meaningful_words = []\n",
    "    with open ('stopword.txt','r') as s:\n",
    "        list_stop_words = s.read().split() #讀取stoplist\n",
    "    for m in list:\n",
    "        if m not in list_stop_words:\n",
    "            list_meaningful_words.append(m)\n",
    "    return list_meaningful_words\n",
    "    \n",
    "def words_frequency(list):\n",
    "    dict_words_frequency={}\n",
    "    for m in list:\n",
    "        dict_words_frequency[m]=list.count(m)\n",
    "    return dict_words_frequency\n",
    "\n",
    "def update_dict(dict0,dict1): #兩個txt中的frequency相加\n",
    "    for k,v in dict1.items():\n",
    "        if dict0.__contains__(k):\n",
    "            dict0[k] += v\n",
    "        else:\n",
    "            dict0.update({k : dict1[k]})\n",
    "\n",
    "def rank_frequency(dict): #根據frequency排序\n",
    "    dict_frequency_rank={}\n",
    "    rank = sorted(dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    for m in range(0,len(rank)):\n",
    "        dict_frequency_rank.update({rank[m][0]:rank[m][1]})\n",
    "    return dict_frequency_rank\n",
    "\n",
    "def write_cvs(dict):\n",
    "    with open('keywords_frequency.csv','w',newline='') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        header = ['keyword','frequency']\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords in all files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beijing</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tariffs</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>against</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deal</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keywords in all files\n",
       "china                         93\n",
       "trade                         58\n",
       "chinese                       51\n",
       "war                           38\n",
       "trump                         32\n",
       "beijing                       25\n",
       "tariffs                       22\n",
       "would                         22\n",
       "said                          20\n",
       "more                          18\n",
       "against                       16\n",
       "president                     15\n",
       "america                       15\n",
       "american                      14\n",
       "deal                          14"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./\"\n",
    "list_txt,n = list_documents(path)\n",
    "dict_accumulative_frequency = {}\n",
    "dict_list_frequency = {}\n",
    "for i in list_txt:\n",
    "    with open(i,'r') as t:\n",
    "        text = t.read()\n",
    "    dict_list_frequency[i] = rank_frequency(words_frequency(extract_meaningful(kill_punctuations_capitals(text))))\n",
    "    update_dict(dict_accumulative_frequency,dict_list_frequency[i])\n",
    "\n",
    "dict_frequency_rank = rank_frequency(dict_accumulative_frequency)\n",
    "write_cvs(dict_frequency_rank)\n",
    "    \n",
    "pd.DataFrame({'keywords in all files':pd.Series(dict_frequency_rank)}).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:trump\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trade-wars-news1.txt</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade-wars-news2.txt</th>\n",
       "      <td>[15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade-wars-news3.txt</th>\n",
       "      <td>[0, 3, 4, 8, 11, 14, 16, 17, 18, 20, 21, 32, 33, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade-wars-news4.txt</th>\n",
       "      <td>[3, 4, 9, 10, 18, 19, 20, 24, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade-wars-news5.txt</th>\n",
       "      <td>[2, 14, 15, 17, 18, 19, 20, 21, 22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 paragraph\n",
       "trade-wars-news1.txt                                                    []\n",
       "trade-wars-news2.txt                                              [15, 25]\n",
       "trade-wars-news3.txt  [0, 3, 4, 8, 11, 14, 16, 17, 18, 20, 21, 32, 33, 35]\n",
       "trade-wars-news4.txt                     [3, 4, 9, 10, 18, 19, 20, 24, 27]\n",
       "trade-wars-news5.txt                   [2, 14, 15, 17, 18, 19, 20, 21, 22]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def locate_word(word,text):\n",
    "    list_paragraphs_contain_word = []\n",
    "    list_paragraphs_text = text.lower().split('\\n')\n",
    "    while '' in list_paragraphs_text:\n",
    "        list_paragraphs_text.remove('')\n",
    "    for i in range(0,len(list_paragraphs_text)):\n",
    "        if list_paragraphs_text[i].find(word) > -1:\n",
    "            list_paragraphs_contain_word.append(i)\n",
    "    return list_paragraphs_contain_word\n",
    "\n",
    "word = input('word:')\n",
    "path = \"./\"\n",
    "list_txt, n = list_documents(path)\n",
    "dict_words_location = {}\n",
    "for i in list_txt:\n",
    "    with open(i,'r') as t:\n",
    "        text = t.read()\n",
    "    dict_words_location[i] = locate_word(word,text)\n",
    "\n",
    "data=pd.Series(dict_words_location)\n",
    "pd.DataFrame({'paragraph':data})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
