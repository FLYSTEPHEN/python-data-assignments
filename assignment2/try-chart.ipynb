{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DJ世界分布\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "df_geo = pd.read_csv('reference/geopy-raw.csv')\n",
    "\n",
    "df_geo['text'] = df_0d['name'] + '<br>institution:' + df_0d['institution'] + '<br>city:'\\\n",
    "+ df_0d['city'] + '<br>contribution:' + df_0d['contribution_sum'].astype(str)\n",
    "\n",
    "scl = [ [0,\"rgb(5, 10, 112)\"],[0.4,\"rgb(40, 60, 190)\"],[0.55,\"rgb(70, 100, 245)\"],\\\n",
    "    [0.7,\"rgb(90, 120, 245)\"],[0.85,\"rgb(106, 137, 247)\"],[0.99,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"] ]\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'ISO-3',\n",
    "        lon = df_geo['lon'],  #\n",
    "        lat = df_geo['lat'],  #\n",
    "        text = df_geo['text'],  #\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 15,\n",
    "            opacity = 0.8,\n",
    "            reversescale = True,\n",
    "            autocolorscale = False,\n",
    "            symbol = 'square',\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "            colorscale = scl,\n",
    "            cmin = 0,\n",
    "            color = df_0d['contribution_sum'],  #\n",
    "            cmax = 2000,  #\n",
    "            colorbar=dict(\n",
    "                title=\"Incoming flightsFebruary 2011\"\n",
    "            )\n",
    "        ))]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Map 1: Global Data Journalist Distribution<br>(Hover for airport names)',\n",
    "        colorbar = True,\n",
    "        geo = dict(\n",
    "#             scope='usa',\n",
    "#             projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='d3-airports' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "from dateutil.parser import parse\n",
    "df_gh = pd.read_csv(\n",
    "    'reference/journalists-data-including-github-contributions.csv'\n",
    ").T  #geopy-raw.csv是上一cell中导出的记者地址原始数据\n",
    "# df_0d = df_gh.reindex(\n",
    "#     ['name','institution','city','github'],axis=1)\n",
    "# df_0d['contribution_sum'] = df_gh.iloc[:,4:].aggregate('sum',axis=1).astype(\"int\")\n",
    "# df_0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#美国求职市场分布\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "df_selected_jobs = pd.read_csv(\"reference/0 jobs.csv\")\n",
    "list_state_code=[]\n",
    "df_count=pd.read_csv('reference/US-States.csv',index_col='code').T\n",
    "for i in df_selected_jobs[\"Location\"]:\n",
    "    try: \n",
    "        list_state_code.append(i.split(', ')[1][:2])\n",
    "    except:\n",
    "        pass\n",
    "list_state_code\n",
    "for i in range(len(list_state_code)):\n",
    "    list_state_code[i]=list_state_code[i].upper()\n",
    "    if list_state_code[i]=='D.' or list_state_code[i]=='DC':\n",
    "        list_state_code[i]='VA'\n",
    "\n",
    "for i in list_state_code:\n",
    "    df_count[i][1]=list_state_code.count(i)\n",
    "df_count\n",
    "code=list(df_count.columns)\n",
    "value=list(df_count.loc['data'])\n",
    "\n",
    "scl = [[0.0, 'rgb(245,245,245)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(158,189,220)'],\\\n",
    "            [0.6, 'rgb(128,154,210)'],[0.8, 'rgb(97,107,200)'],[1.0, 'rgb(64,39,190)']]\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = code,\n",
    "        z = value,\n",
    "        locationmode = 'USA-states',\n",
    "        text = code,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"how many positions\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'U.S journalism jobs',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, filename='d3-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#世界DJ高校\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "df_geo = pd.read_csv('reference/geopy-raw.csv')\n",
    "\n",
    "df_geo['text'] = df_0d['name'] + '<br>institution:' + df_0d['institution'] + '<br>city:'\\\n",
    "+ df_0d['city'] + '<br>contribution:' + df_0d['contribution_sum'].astype(str)\n",
    "\n",
    "scl = [ [0,\"rgb(5, 10, 112)\"],[0.4,\"rgb(40, 60, 190)\"],[0.55,\"rgb(70, 100, 245)\"],\\\n",
    "    [0.7,\"rgb(90, 120, 245)\"],[0.85,\"rgb(106, 137, 247)\"],[0.99,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"] ]\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'ISO-3',\n",
    "        lon = df_geo['lon'],  #\n",
    "        lat = df_geo['lat'],  #\n",
    "        text = df_geo['text'],  #\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            opacity = 0.8,\n",
    "            reversescale = True,\n",
    "            autocolorscale = False,\n",
    "            symbol = 'square',\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "            colorscale = scl,\n",
    "            cmin = 0,\n",
    "            color = df_0d['contribution_sum'],  #\n",
    "            cmax = 2000,  #\n",
    "            colorbar=dict(\n",
    "                title=\"Incoming flightsFebruary 2011\"\n",
    "            )\n",
    "        ))]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Most trafficked US airports<br>(Hover for airport names)',\n",
    "        colorbar = True,\n",
    "        geo = dict(\n",
    "#             scope='usa',\n",
    "#             projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='d3-airports' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DJ世界分布\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "df_geo = pd.read_csv('reference/geopy-raw.csv')\n",
    "\n",
    "df_geo['text'] = df_0d['name'] + '<br>institution:' + df_0d['institution'] + '<br>city:'\\\n",
    "+ df_0d['city'] + '<br>contribution:' + df_0d['contribution_sum'].astype(str)\n",
    "\n",
    "scl = [ [0,\"rgb(5, 10, 112)\"],[0.4,\"rgb(40, 60, 190)\"],[0.55,\"rgb(70, 100, 245)\"],\\\n",
    "    [0.7,\"rgb(90, 120, 245)\"],[0.85,\"rgb(106, 137, 247)\"],[0.99,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"] ]\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'ISO-3',\n",
    "        lon = df_geo['lon'],  #\n",
    "        lat = df_geo['lat'],  #\n",
    "        text = df_geo['text'],  #\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 15,\n",
    "            opacity = 0.8,\n",
    "            reversescale = True,\n",
    "            autocolorscale = False,\n",
    "            symbol = 'square',\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "            colorscale = scl,\n",
    "            cmin = 0,\n",
    "            color = df_0d['contribution_sum'],  #\n",
    "            cmax = 2000,  #\n",
    "            colorbar=dict(\n",
    "                title=\"Incoming flightsFebruary 2011\"\n",
    "            )\n",
    "        ))]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Most trafficked US airports<br>(Hover for airport names)',\n",
    "        colorbar = True,\n",
    "        geo = dict(\n",
    "#             scope='usa',\n",
    "#             projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='d3-airports' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.barplot(\n",
    "    x='contribution_sum',\n",
    "    y='name',\n",
    "    data=df_0d.sort_values(\n",
    "        by=['contribution_sum'], axis = 0, ascending = False\n",
    "        ).head(15),\n",
    "    palette=sns.cubehelix_palette(\n",
    "        15, start=2.7, rot=0.04, dark=0.2, light=0.9, reverse=True\n",
    "        ), #palette is like the color combination style\n",
    "    saturation = 1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = sns.scatterplot(\n",
    "    x='count',\n",
    "    y='contribution_sum',\n",
    "    data=df_code_country_data,\n",
    "    palette=sns.cubehelix_palette(\n",
    "        10, start=2.7, rot=0.04, dark=0.2, light=0.9, reverse=True\n",
    "    ), #palette is like the color combination style\n",
    "    ax=axes[1,0]) \n",
    "ax3.set_title('Global Data Journalist Distribution', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#美国求职市场分布\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "\n",
    "df_selected_jobs = pd.read_csv(\"reference/0 jobs.csv\")\n",
    "list_state_code=[]\n",
    "dict_count={}\n",
    "for i in df_selected_jobs[\"Location\"]:\n",
    "    try: \n",
    "        list_state_code.append(i.split(', ')[1][:2])\n",
    "    except:\n",
    "        pass\n",
    "for i in range(len(list_state_code)):\n",
    "    list_state_code[i]=list_state_code[i].upper()\n",
    "    if list_state_code[i]=='D.':\n",
    "        list_state_code[i]='DC'\n",
    "for i in list_state_code:\n",
    "    dict_count[i]=list_state_code.count(i)\n",
    "code=list(dict_count.keys())\n",
    "value=list(dict_count.values())\n",
    "len(value)\n",
    "# for col in df.columns:\n",
    "#     df[col] = df[col].astype(str)\n",
    "\n",
    "\n",
    "# scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n",
    "#             [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n",
    "# data = [ dict(\n",
    "#         type='choropleth',\n",
    "#         colorscale = scl,\n",
    "#         autocolorscale = False,\n",
    "#         locations = code,\n",
    "#         z = value,\n",
    "#         locationmode = 'USA-states',\n",
    "#         text = code,\n",
    "#         marker = dict(\n",
    "#             line = dict (\n",
    "#                 color = 'rgb(255,255,255)',\n",
    "#                 width = 2\n",
    "#             ) ),\n",
    "#         colorbar = dict(\n",
    "#             title = \"how many positions\")\n",
    "#         ) ]\n",
    "\n",
    "# layout = dict(\n",
    "#         title = 'U.S journalism jobs',\n",
    "#         geo = dict(\n",
    "#             scope='usa',\n",
    "#             projection=dict( type='albers usa' ),\n",
    "#             showlakes = True,\n",
    "#             lakecolor = 'rgb(255, 255, 255)'),\n",
    "#              )\n",
    "    \n",
    "# fig = dict( data=data, layout=layout )\n",
    "# py.iplot( fig, filename='d3-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "list_raw=[]\n",
    "geolocator = Nominatim(user_agent=\"my-application\")\n",
    "df_dj = pd.read_csv(\"reference/journalists-data.csv\",\n",
    "            names=['name','agency','location','github'])\n",
    "for i in df_dj['location']:\n",
    "    location=geolocator.geocode(i, language='en',timeout=60)\n",
    "    list_raw.append(location.raw)\n",
    "    time.sleep(2)\n",
    "df = pd.DataFrame(list_raw)\n",
    "df.to_csv('reference/geopy-raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".head(10).plot(\n",
    "    kind ='barh',\n",
    "    title = 'Global Data Journalist Distribution',\n",
    "    grid = True,\n",
    "    figsize = (12,5),\n",
    "#     rot = 45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f61af6a13950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_gh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_gh' is not defined"
     ]
    }
   ],
   "source": [
    "df_gh.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chao/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_gh['datetime'] = df_gh.index\n",
    "df_gh.tail(3959)['datetime'] = df_gh.tail(3959)['datetime'].apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                  name\n",
       "institution    institution\n",
       "city                  city\n",
       "github              github\n",
       "2018-11-04      2018-11-04\n",
       "2018-11-03      2018-11-03\n",
       "2018-11-02      2018-11-02\n",
       "2018-11-01      2018-11-01\n",
       "2018-10-31      2018-10-31\n",
       "2018-10-30      2018-10-30\n",
       "2018-10-29      2018-10-29\n",
       "2018-10-28      2018-10-28\n",
       "2018-10-27      2018-10-27\n",
       "2018-10-26      2018-10-26\n",
       "2018-10-25      2018-10-25\n",
       "2018-10-24      2018-10-24\n",
       "2018-10-23      2018-10-23\n",
       "2018-10-22      2018-10-22\n",
       "2018-10-21      2018-10-21\n",
       "2018-10-20      2018-10-20\n",
       "2018-10-19      2018-10-19\n",
       "2018-10-18      2018-10-18\n",
       "2018-10-17      2018-10-17\n",
       "2018-10-16      2018-10-16\n",
       "2018-10-15      2018-10-15\n",
       "2018-10-14      2018-10-14\n",
       "2018-10-13      2018-10-13\n",
       "2018-10-12      2018-10-12\n",
       "2018-10-11      2018-10-11\n",
       "2018-10-10      2018-10-10\n",
       "                  ...     \n",
       "2008-01-28      2008-01-28\n",
       "2008-01-27      2008-01-27\n",
       "2008-01-26      2008-01-26\n",
       "2008-01-25      2008-01-25\n",
       "2008-01-24      2008-01-24\n",
       "2008-01-23      2008-01-23\n",
       "2008-01-22      2008-01-22\n",
       "2008-01-21      2008-01-21\n",
       "2008-01-20      2008-01-20\n",
       "2008-01-19      2008-01-19\n",
       "2008-01-18      2008-01-18\n",
       "2008-01-17      2008-01-17\n",
       "2008-01-16      2008-01-16\n",
       "2008-01-15      2008-01-15\n",
       "2008-01-14      2008-01-14\n",
       "2008-01-13      2008-01-13\n",
       "2008-01-12      2008-01-12\n",
       "2008-01-11      2008-01-11\n",
       "2008-01-10      2008-01-10\n",
       "2008-01-09      2008-01-09\n",
       "2008-01-08      2008-01-08\n",
       "2008-01-07      2008-01-07\n",
       "2008-01-06      2008-01-06\n",
       "2008-01-05      2008-01-05\n",
       "2008-01-04      2008-01-04\n",
       "2008-01-03      2008-01-03\n",
       "2008-01-02      2008-01-02\n",
       "2008-01-01      2008-01-01\n",
       "2007-12-31      2007-12-31\n",
       "2007-12-30      2007-12-30\n",
       "Name: datetime, Length: 3967, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gh['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2139fe192f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_gh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(self, rule, how, axis, fill_method, closed, label, convention, kind, loffset, limit, base, on, level)\u001b[0m\n\u001b[1;32m   7108\u001b[0m                      \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m                      \u001b[0mconvention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7110\u001b[0;31m                      base=base, key=on, level=level)\n\u001b[0m\u001b[1;32m   7111\u001b[0m         return _maybe_process_deprecations(r,\n\u001b[1;32m   7112\u001b[0m                                            \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;34m\"\"\" create a TimeGrouper and return our resampler \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         raise TypeError(\"Only valid with DatetimeIndex, \"\n\u001b[1;32m   1275\u001b[0m                         \u001b[0;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                         \"but got an instance of %r\" % type(ax).__name__)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "df_gh.resample('1w').aggregate('sum').plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
