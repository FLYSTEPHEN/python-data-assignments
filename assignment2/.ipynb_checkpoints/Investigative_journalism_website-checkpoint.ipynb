{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "url='https://gijn.org/member/'\n",
    "my_headers = [\n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)\",\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11',\n",
    "    'Opera/9.25 (Windows NT 5.1; U; en)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)',\n",
    "    'Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)',\n",
    "    'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12',\n",
    "    'Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9',\n",
    "    \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_menber(url,headers):\n",
    "    r = requests.get(url, headers=headers)\n",
    "    list_members = []\n",
    "    mypage=BeautifulSoup(r.text,\"html.parser\")\n",
    "    all_div = [i.div for i in mypage.find_all('article')]\n",
    "    for i in all_div:\n",
    "        member=[]\n",
    "        member.append(i.header.h2.text.strip())\n",
    "        member.append(i.header.h5.text.strip())\n",
    "        member.append(i.footer.text.strip().replace('Website: ',''))\n",
    "        member.append(i.div.text.strip())\n",
    "        list_members.append(member)\n",
    "    return list_members, len(all_div)\n",
    "\n",
    "headers = {'user-agent': 'my-app/0.0.1'}\n",
    "basic_url = 'https://gijn.org/member/page/'\n",
    "starting_index = 1\n",
    "step = 1\n",
    "page_index = starting_index\n",
    "all_members = []\n",
    "while True:\n",
    "    url = '{}{}'.format(basic_url,page_index)\n",
    "    try:\n",
    "        info = scrape_menber(url,headers)\n",
    "        members, len_page_members = info[0], info[1]\n",
    "    except:\n",
    "        members, len_page_members = [], 1\n",
    "    print(members)\n",
    "    all_members.extend(members)\n",
    "    page_index += step\n",
    "    if len_page_members == 0:\n",
    "        break\n",
    "\n",
    "header = ['title','founded','website','description']\n",
    "df = pd.DataFrame(columns = header)\n",
    "df = df.append(all_members,ignore_index=True)\n",
    "df.to_csv('members.csv',na_rep='NaN',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
