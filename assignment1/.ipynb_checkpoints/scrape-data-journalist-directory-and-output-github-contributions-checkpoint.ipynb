{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取數據新聞新聞記者名單和信息\n",
    "import csv\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "def get_dynamic_page_script(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(2)\n",
    "    h = browser.find_element_by_css_selector('html')\n",
    "    t = h.get_attribute('innerHTML')\n",
    "    browser.quit()\n",
    "    return t\n",
    "#這個網站用requests拿不到腳本，因此用selenium\n",
    "\n",
    "\n",
    "def scrape_directory(page_script):\n",
    "    mypage=BeautifulSoup(page_script,\"html.parser\")\n",
    "    journalists_data = []\n",
    "    for i in mypage.find_all('div', attrs={'class':\"back\"}):\n",
    "        journalist = []\n",
    "        journalist.append(i.find('div', attrs={'class':\"name\"}).text)\n",
    "        journalist.append(i.find('div', attrs={'class':\"institution\"}).text)\n",
    "        journalist.append(i.find('div', attrs={'class':\"city\"}).text)\n",
    "        journalist.append(i.find('div', attrs={'class':\"github\"}).a['href'])\n",
    "#         journalist.append(i.find('div', attrs={'class':\"pgp\"}).a.text)\n",
    "#         journalist.append(i.find('div', attrs={'class':\"email\"}).a['href'].replace('mailto:', ''))\n",
    "#         journalist.append(i.find('div', attrs={'class':\"twitter\"}).a['href'])\n",
    "#         journalist.append(i.find('div', attrs={'class':\"website\"}).a['href'])\n",
    "# 經測試，動態爬尋的速度太慢了，最後還是選擇用靜態爬，此處供以後參考\n",
    "#     for i in browser.find_elements_by_class_name(\"back\"):\n",
    "#         journalist = []\n",
    "#         journalist.append(i.find_element_by_class_name(\"name\").text)\n",
    "#         journalist.append(i.find_element_by_class_name(\"institution\").text)\n",
    "#         journalist.append(i.find_element_by_class_name(\"city\").text)\n",
    "#         journalist.append(i.find_element_by_xpath(\"//div[@class='pgp']/a\").text)\n",
    "#         journalist.append(i.find_element_by_xpath(\"//div[@class='email']/a\").get_attribute('href').replace('mailto:', ''))\n",
    "#         journalist.append(i.find_element_by_xpath(\"//div[@class='twitter']/a\").get_attribute('href'))\n",
    "#         journalist.append(i.find_element_by_xpath(\"//div[@class='github']/a\").get_attribute('href'))\n",
    "#         journalist.append(i.find_element_by_xpath(\"//div[@class='website']/a\").get_attribute('href'))\n",
    "#     journalists_data.append(journalist)\n",
    "    \n",
    "    #因為原網站已經有N/A了，所以在這裡把空信息轉化成N/A，統一格式\n",
    "        for i, value in enumerate(journalist):\n",
    "            if value == '':\n",
    "                journalist[i]='N/A'\n",
    "        journalists_data.append(journalist)\n",
    "    return journalists_data\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://jplusplus.github.io/global-directory/'\n",
    "page_script = get_dynamic_page_script(url)\n",
    "journalists_data = scrape_directory(page_script)\n",
    "with open('journalists-data.csv','w') as f:\n",
    "    csv.writer(f).writerows(journalists_data)\n",
    "# 輸出完整的記者基本信息表csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.2 s, sys: 1.34 s, total: 57.5 s\n",
      "Wall time: 25min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 根據之前導出的csv中每位記者的github網址，爬取他們的contribution歷史\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime \n",
    "import time\n",
    "\n",
    "\n",
    "def scrape_github_contributions(homepage_url):\n",
    "#今後只要有一個人的github的homepage_url,就可以爬取所有contribution了\n",
    "    def scrpe_year_urls(homepage_url):\n",
    "        year_urls = [homepage_url] \n",
    "        #2018年（今年）在homepage上可以截止到今天，但如果載入html中的地址，會截止到今年12-31（未來），所以先把首頁加進去\n",
    "        r = requests.get(homepage_url).text\n",
    "        home_page_script = BeautifulSoup(r,\"html.parser\")\n",
    "        for i in home_page_script.find_all('a',attrs={'class':\"js-year-link filter-item px-3 mb-2 py-2 \"}):\n",
    "        #這個class不包含2018年（今年）\n",
    "            url ='{}{}'.format('https://github.com',i['href'])\n",
    "            year_urls.append(url)\n",
    "        return year_urls\n",
    "    \n",
    "    def scrape_one_year_contributions(url):\n",
    "        r = requests.get(url).text\n",
    "        page_script = BeautifulSoup(r,\"html.parser\")\n",
    "        all_rects = page_script.find_all('rect')\n",
    "        for i in reversed(all_rects):\n",
    "            contributions[i['data-date']] = i['data-count']\n",
    "    # 因為不同年份的每一頁在12.30這一天顯示有重複（每一年都會顯示到去年的12.30左右），所以用dict的key的不可重複性避免這個問題   \n",
    "            \n",
    "    contributions = {} \n",
    "    for i in scrpe_year_urls(homepage_url): \n",
    "        scrape_one_year_contributions(i)\n",
    "    contributions_list = list(contributions.values())\n",
    "    #dict.values輸出的不是list，要重新列表化，方便之後輸出\n",
    "    return contributions_list\n",
    "\n",
    "\n",
    "def write_head(beginDate): #添加標題行\n",
    "    def dateRange(beginDate, endDate): #引用網絡上的，黑箱！\n",
    "        dates = []\n",
    "        dt = datetime.datetime.strptime(beginDate, \"%Y-%m-%d\")\n",
    "        date = beginDate[:]\n",
    "        while date <= endDate:\n",
    "            dates.append(date)\n",
    "            dt = dt + datetime.timedelta(1)\n",
    "            date = dt.strftime(\"%Y-%m-%d\")\n",
    "        return reversed(dates)\n",
    "    #return一個從現在到以前的日期列表，用來作為csv文件的head的一部分，之後每一個日期的數據只佔一格\n",
    "#     head = [\"name\",\"institution\",\"city\",\"pgp\",\"email\",\"twitter\",\"website\",\"github\"]\n",
    "    head = [\"name\",\"institution\",\"city\",\"github\"]\n",
    "    today = time.strftime(\"%Y-%m-%d\")\n",
    "    head.extend(dateRange(beginDate, today))\n",
    "    return head\n",
    "\n",
    "\n",
    "\n",
    "with open('journalists-data.csv','r') as f:  #讀取上一部分輸出的記者基本信息表\n",
    "    with open('journalists-data-including-github-contributions.csv','a') as d:\n",
    "        csv.writer(d).writerow(write_head('2007-12-30')) #github是08年發布的，但顯示最早到20171230，所以從這個日期開始爬\n",
    "        for row in csv.reader(f):\n",
    "            try:\n",
    "                row.extend(scrape_github_contributions(row[3])) #row[3]是每位記者的github地址\n",
    "                csv.writer(d).writerow(row)\n",
    "            except:\n",
    "                row.append('N/A') \n",
    "                #疑問：對於沒有github的記者，應該所有日期的contribution全部標註為N/A還是0？這個可以之後再定\n",
    "                csv.writer(d).writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>209</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Justin Myers</td>\n",
       "      <td>Annabel Church</td>\n",
       "      <td>...</td>\n",
       "      <td>Pierre Romera</td>\n",
       "      <td>Cosmin Cabulea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution</th>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Journalism++</td>\n",
       "      <td>Freelance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>United States, Brooklyn (US-VA)</td>\n",
       "      <td>N/A, Germany</td>\n",
       "      <td>...</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>Bonn, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>http://github.com/myersjustinc</td>\n",
       "      <td>http://www.github.com/arc64</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.github.com/pirhoo</td>\n",
       "      <td>http://www.github.com/pushthings4ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3967 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         1                            4    \\\n",
       "name                            Justin Myers               Annabel Church   \n",
       "institution             The Associated Press                          NaN   \n",
       "city         United States, Brooklyn (US-VA)                 N/A, Germany   \n",
       "github        http://github.com/myersjustinc  http://www.github.com/arc64   \n",
       "2018-11-04                                 0                            0   \n",
       "2018-11-03                                 0                            0   \n",
       "2018-11-02                                 0                            0   \n",
       "2018-11-01                                 0                            0   \n",
       "2018-10-31                                 0                            1   \n",
       "2018-10-30                                 0                            0   \n",
       "...                                      ...                          ...   \n",
       "2008-01-08                               NaN                          NaN   \n",
       "2008-01-07                               NaN                          NaN   \n",
       "2008-01-06                               NaN                          NaN   \n",
       "2008-01-05                               NaN                          NaN   \n",
       "2008-01-04                               NaN                          NaN   \n",
       "2008-01-03                               NaN                          NaN   \n",
       "2008-01-02                               NaN                          NaN   \n",
       "2008-01-01                               NaN                          NaN   \n",
       "2007-12-31                               NaN                          NaN   \n",
       "2007-12-30                               NaN                          NaN   \n",
       "\n",
       "                             ...                    \\\n",
       "name                         ...                     \n",
       "institution                  ...                     \n",
       "city                         ...                     \n",
       "github                       ...                     \n",
       "2018-11-04                   ...                     \n",
       "2018-11-03                   ...                     \n",
       "2018-11-02                   ...                     \n",
       "2018-11-01                   ...                     \n",
       "2018-10-31                   ...                     \n",
       "2018-10-30                   ...                     \n",
       "...                          ...                     \n",
       "2008-01-08                   ...                     \n",
       "2008-01-07                   ...                     \n",
       "2008-01-06                   ...                     \n",
       "2008-01-05                   ...                     \n",
       "2008-01-04                   ...                     \n",
       "2008-01-03                   ...                     \n",
       "2008-01-02                   ...                     \n",
       "2008-01-01                   ...                     \n",
       "2007-12-31                   ...                     \n",
       "2007-12-30                   ...                     \n",
       "\n",
       "                                      209  \\\n",
       "name                        Pierre Romera   \n",
       "institution                  Journalism++   \n",
       "city                        Paris, France   \n",
       "github       http://www.github.com/pirhoo   \n",
       "2018-11-04                              0   \n",
       "2018-11-03                              0   \n",
       "2018-11-02                             13   \n",
       "2018-11-01                              0   \n",
       "2018-10-31                             17   \n",
       "2018-10-30                             18   \n",
       "...                                   ...   \n",
       "2008-01-08                            NaN   \n",
       "2008-01-07                            NaN   \n",
       "2008-01-06                            NaN   \n",
       "2008-01-05                            NaN   \n",
       "2008-01-04                            NaN   \n",
       "2008-01-03                            NaN   \n",
       "2008-01-02                            NaN   \n",
       "2008-01-01                            NaN   \n",
       "2007-12-31                            NaN   \n",
       "2007-12-30                            NaN   \n",
       "\n",
       "                                               213  \n",
       "name                                Cosmin Cabulea  \n",
       "institution                              Freelance  \n",
       "city                                 Bonn, Germany  \n",
       "github       http://www.github.com/pushthings4ward  \n",
       "2018-11-04                                       0  \n",
       "2018-11-03                                       0  \n",
       "2018-11-02                                       0  \n",
       "2018-11-01                                       0  \n",
       "2018-10-31                                       0  \n",
       "2018-10-30                                       0  \n",
       "...                                            ...  \n",
       "2008-01-08                                     NaN  \n",
       "2008-01-07                                     NaN  \n",
       "2008-01-06                                     NaN  \n",
       "2008-01-05                                     NaN  \n",
       "2008-01-04                                     NaN  \n",
       "2008-01-03                                     NaN  \n",
       "2008-01-02                                     NaN  \n",
       "2008-01-01                                     NaN  \n",
       "2007-12-31                                     NaN  \n",
       "2007-12-30                                     NaN  \n",
       "\n",
       "[3967 rows x 81 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', 5)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', 20)\n",
    "df=pd.read_csv('journalists-data-including-github-contributions.csv')\n",
    "df=df[np.isnan(df['2018-11-04']) == False].T #2018-11-04如果為N/A，則說明此人沒有github\n",
    "df.to_csv('Result.csv') #寫出的文件中contributions是float，還不知道怎麼變成整數\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
